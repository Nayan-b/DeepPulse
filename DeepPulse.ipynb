{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ggw0W9-jwABw"
      },
      "source": [
        "# DeepPulse\n",
        "## An Uncertainty-aware Deep Neural Network for Heart Rate Estimations from Wrist-worn Photoplethysmography\n",
        "> 2022 44th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)\n",
        "\n",
        "- [Paper](https://ieeexplore.ieee.org/document/9871813) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Install Packages"
      ],
      "metadata": {
        "id": "jOKj__n6UAnG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GlvbszNNwY60"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow-addons\n",
        "!pip install git+https://github.com/uncertainty-toolbox/uncertainty-toolbox"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Download Datasets"
      ],
      "metadata": {
        "id": "iLDPNneWTOXM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#BAMI\n",
        "!gdown 1g5gqh6vekEdi3ZT21Cdu_1fkfNjBeUOA"
      ],
      "metadata": {
        "id": "U8m6tEVDTENo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#DALIA\n",
        "!gdown 12DnrzMCV_otfU5_YUbedwRRcIyiHShIm"
      ],
      "metadata": {
        "id": "gutgm2TBTWVJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#IEEE Test\n",
        "!gdown 1PSciZgnXPlsYBMzR1Oj4TjcTk_LjL7TQ\n",
        "\n",
        "#IEEE Train\n",
        "!gdown 174KyqOiuhl3Prsrn29KgeMmIJVgYLSQK"
      ],
      "metadata": {
        "id": "1RvxpJXZTWM_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Imports"
      ],
      "metadata": {
        "id": "Wr4RBLTzUhgz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PAcl7MIQwlBS"
      },
      "outputs": [],
      "source": [
        "#Import Necessary Packages\n",
        "#util libs\n",
        "import pickle\n",
        "import os\n",
        "import random\n",
        "import time\n",
        "#dl libs\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "import tensorflow.keras as keras\n",
        "from keras.callbacks import Callback\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import regularizers\n",
        "#deeplearning addtional libs\n",
        "import tensorflow_probability as tfp \n",
        "tfd = tfp.distributions\n",
        "import uncertainty_toolbox as uct\n",
        "#computation libs\n",
        "import scipy.signal as sci_sig\n",
        "import pandas as pd\n",
        "from scipy import stats\n",
        "import numpy as np\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn import preprocessing \n",
        "from sklearn.model_selection import train_test_split\n",
        "import fnmatch\n",
        "import itertools\n",
        "import re\n",
        "from pathlib import Path\n",
        "#display libs\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.gridspec import GridSpec\n",
        "from matplotlib.backends.backend_pdf import PdfPages\n",
        "import matplotlib as mpl\n",
        "from matplotlib.transforms import Bbox\n",
        "import seaborn as sns\n",
        "from tqdm.notebook import tqdm_notebook, tqdm, trange\n",
        "from google.colab import output\n",
        "\n",
        "print(\"Tensorflow Version: \", tf.__version__)\n",
        "print(\"Built with CUDA: \", tf.test.is_built_with_cuda())\n",
        "print(\"CPUs: \", tf.config.list_physical_devices('CPU'))\n",
        "print(\"GPUs: \", tf.config.list_physical_devices('GPU'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AJK8zoxfNDhe"
      },
      "source": [
        "### Experiment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ckip58rtBYd_"
      },
      "outputs": [],
      "source": [
        "########### PREPROCESSING VARIABLES ##################\n",
        "BAND_PASS_LOW = 0.5\n",
        "BAND_PASS_HIGH = 4.5\n",
        "BAND_PASS_ORDER = 2\n",
        "RESAMPLE_FS = 64\n",
        "\n",
        "########### ARCHITECTURAL VARIABLES ##################\n",
        "SENSOR_FILTER_SIZE = 16\n",
        "SENSOR_NUM_FILTER = 64\n",
        "SENSOR_DROPOUT = 0.15 \n",
        "SENSOR_CONV_TYPE = \"Normal\"\n",
        "GLOBAL_FILTER_SIZE = 16\n",
        "GLOBAL_NUM_FILTER = 128\n",
        "GLOBAL_DROPOUT = 0.15\n",
        "GLOBAL_CONV_TYPE = \"Normal\"\n",
        "RECURRENT_UNITS = 32\n",
        "RECURRENT_DROPOUT = 0.15\n",
        "MAXPOOLING = 2\n",
        "\n",
        "########### TRAINING VARIABLES ##################\n",
        "NUM_EPOCHS = 200\n",
        "BATCH_SIZE = 32\n",
        "STRATIFIED = True\n",
        "TEST_SIZE= 0.33\n",
        "NUM_PREDICT_SAMPLES = 25\n",
        "OPTIMISER = tf.optimizers.Nadam()\n",
        "EXP_NAME = [\"IEEE\", \"BAMI\", \"DALIA\"]\n",
        "PATH = '/content/drive/MyDrive/DeepPulse/Exp/'\n",
        "\n",
        "########### OUTPUT VARIABLES ##################\n",
        "DISPLAY = False\n",
        "PUBLICATION = False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########### DATA ##################\n",
        "infile = open(\"/content/BAMI_Data\",'rb')\n",
        "BAMI_Data = pickle.load(infile)\n",
        "infile.close()\n",
        "infile = open(\"/content/DaLia_Data\",'rb')\n",
        "DaLia_Data = pickle.load(infile)\n",
        "infile.close()\n",
        "infile = open(\"/content/IEEE_Test_Data\",'rb')\n",
        "IEEE_Test_Data = pickle.load(infile)\n",
        "infile.close()\n",
        "infile = open(\"/content/IEEE_Train_Data\",'rb')\n",
        "IEEE_Train_Data = pickle.load(infile)\n",
        "infile.close()\n",
        "IEEE_Data = IEEE_Train_Data + IEEE_Test_Data\n",
        "DATA = [IEEE_Data, BAMI_Data, DaLia_Data]"
      ],
      "metadata": {
        "id": "oD6pM5odUomV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_DeepPulse(SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, SENSOR_DROPOUT, \n",
        "                   GLOBAL_FILTER_SIZE, GLOBAL_NUM_FILTER, \n",
        "                   GLOBAL_DROPOUT, RECURRENT_UNITS, \n",
        "                   RECURRENT_DROPOUT, MAXPOOLING):\n",
        "  keras.backend.clear_session()\n",
        "  #=-=================== INPUTS ================================\n",
        "  input_PPG = keras.Input(shape=(512, 1), name=\"PPG_Sigs\")\n",
        "  input_ACC = keras.Input(shape=(512, 3), name=\"ACC_Sigs\")\n",
        "  \n",
        "  #=-=================== PPG ================================\n",
        "  PPG_SENSOR_CONV_1 = Convolution(SENSOR_NUM_FILTER, SENSOR_FILTER_SIZE, \n",
        "                                  input_PPG, \"PPG_SENSOR_1\")\n",
        "  PPG_SENSOR_CONV_2 = Convolution_MaxPool_DropOut(SENSOR_NUM_FILTER, \n",
        "                              SENSOR_FILTER_SIZE, MAXPOOLING, SENSOR_DROPOUT, \n",
        "                              PPG_SENSOR_CONV_1, \"PPG_SENSOR_2\")\n",
        "\n",
        "  #=-=================== ACC ================================\n",
        "  ACC_SENSOR_CONV_1 = Convolution(SENSOR_NUM_FILTER, SENSOR_FILTER_SIZE,\n",
        "                                  input_ACC, \"ACC_SENSOR_1\")\n",
        "  ACC_SENSOR_CONV_2 = Convolution_MaxPool_DropOut(SENSOR_NUM_FILTER, \n",
        "                              SENSOR_FILTER_SIZE, MAXPOOLING, SENSOR_DROPOUT, \n",
        "                              ACC_SENSOR_CONV_1, \"ACC_SENSOR_2\")\n",
        "  \n",
        "  #=-=================== MERGE ================================\n",
        "  MERGE = layers.Concatenate(axis=2, name=\"MERGE\")([PPG_SENSOR_CONV_2, \n",
        "                                                    ACC_SENSOR_CONV_2])\n",
        "\n",
        "  #=-=================== GLOBAL ================================\n",
        "  GLOBAL_CONV_1 = Convolution_MaxPool_DropOut(GLOBAL_NUM_FILTER, \n",
        "                              GLOBAL_FILTER_SIZE, MAXPOOLING, SENSOR_DROPOUT, \n",
        "                              MERGE, \"GLOBAL_1\")\n",
        "  \n",
        "  GLOBAL_CONV_2 = Convolution_MaxPool_DropOut(GLOBAL_NUM_FILTER, \n",
        "                                              GLOBAL_FILTER_SIZE, MAXPOOLING,\n",
        "                                              GLOBAL_DROPOUT, GLOBAL_CONV_1, \n",
        "                                              \"GLOBAL_2\")\n",
        "    \n",
        "  #=-==========================================================\n",
        "  RECURRENT_1 = LSTM_LayerNorm(RECURRENT_UNITS, RECURRENT_DROPOUT, True, \n",
        "                     GLOBAL_CONV_2, \"RECURRENT_1\")\n",
        "  RECURRENT_2 = LSTM_LayerNorm(RECURRENT_UNITS, RECURRENT_DROPOUT, False, \n",
        "                     RECURRENT_1, \"RECURRENT_2\")\n",
        "  #=-==========================================================\n",
        "  dist = Prediction(GLOBAL_DROPOUT,\"PREDICT\",RECURRENT_2)\n",
        "\n",
        "  DeepPulse = keras.Model(inputs = [input_PPG, input_ACC], outputs = dist, name=\"DeepPulse\")\n",
        "  return DeepPulse"
      ],
      "metadata": {
        "id": "eo20EzYWVz_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ph68GXX_Ptk4"
      },
      "source": [
        "# Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Convolution_MaxPool(SENSOR_NUM_FILTER, SENSOR_FEAT_FILTER_SIZE, MAX_POOLING, \n",
        "                       INPUT, NAME):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Convolutional block with Maxpooling.\n",
        "\n",
        "    Args:\n",
        "        SENSOR_NUM_FILTER: The number of filters in the Convolutional block.\n",
        "        SENSOR_FEAT_FILTER_SIZE: The filter size of the Convolutional block.\n",
        "        MAX_POOLING: The max pooling for the Convolutional block.\n",
        "        INPUT: The input to the Convolutional block.\n",
        "        NAME: The name of the Convolutional block.\n",
        "\n",
        "    Returns:\n",
        "        x: The output of the Convolutional block.\n",
        "    \"\"\"\n",
        "    x = layers.Conv1D(\n",
        "          SENSOR_NUM_FILTER,\n",
        "          SENSOR_FEAT_FILTER_SIZE,\n",
        "          use_bias=False,\n",
        "          name =  NAME +\"_conv\",\n",
        "          padding=\"same\")(INPUT)\n",
        "    x = layers.ReLU(name =  NAME + \"_relu\")(x)\n",
        "    x = layers.BatchNormalization(name =  NAME + \"_batch_norm\")(x)\n",
        "    x = layers.MaxPool1D(MAX_POOLING, name =  NAME + \"_max_pool\")(x)\n",
        "    return x\n",
        "\n",
        "def Convolution_MaxPool_DropOut(SENSOR_NUM_FILTER, SENSOR_FEAT_FILTER_SIZE, \n",
        "                                MAX_POOLING, DROP_RATE, INPUT, NAME):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Convolutional block with Maxpooling & Dropout.\n",
        "\n",
        "    Args:\n",
        "        SENSOR_NUM_FILTER: The number of filters in the Convolutional block.\n",
        "        SENSOR_FEAT_FILTER_SIZE: The filter size of the Convolutional block.\n",
        "        DROP_RATE: The dropout rate for the Convolutional block.\n",
        "        MAX_POOLING: The max pooling for the Convolutional block.\n",
        "        INPUT: The input to the Convolutional block.\n",
        "        NAME: The name of the Convolutional block.\n",
        "\n",
        "    Returns:\n",
        "        x: The output of the Convolutional block.\n",
        "    \"\"\"\n",
        "    x = layers.Conv1D(\n",
        "          SENSOR_NUM_FILTER,\n",
        "          SENSOR_FEAT_FILTER_SIZE,\n",
        "          use_bias=False,\n",
        "          name =  NAME +\"_conv\",\n",
        "          padding=\"same\")(INPUT)\n",
        "    x = layers.ReLU(name =  NAME + \"_relu\")(x)\n",
        "    x = layers.BatchNormalization(name =  NAME + \"_batch_norm\")(x)\n",
        "    x = layers.AveragePooling1D(MAX_POOLING, name =  NAME + \"_max_pool\")(x)\n",
        "    x = layers.Dropout(DROP_RATE, name =  NAME + \"_dropout\")(x, training=True)\n",
        "    return x\n",
        "\n",
        "def Convolution_DropOut(SENSOR_NUM_FILTER, SENSOR_FEAT_FILTER_SIZE, DROP_RATE, \n",
        "                        INPUT, NAME):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Convolutional block with Dropout.\n",
        "\n",
        "    Args:\n",
        "        SENSOR_NUM_FILTER: The number of filters in the Convolutional block.\n",
        "        SENSOR_FEAT_FILTER_SIZE: The filter size of the Convolutional block.\n",
        "        DROP_RATE: The dropout rate for the Convolutional block.\n",
        "        INPUT: The input to the Convolutional block.\n",
        "        NAME: The name of the Convolutional block.\n",
        "\n",
        "    Returns:\n",
        "        x: The output of the Convolutional block.\n",
        "    \"\"\"\n",
        "    x = layers.Conv1D(\n",
        "          SENSOR_NUM_FILTER,\n",
        "          SENSOR_FEAT_FILTER_SIZE,\n",
        "          use_bias=False,\n",
        "          name =  NAME +\"_conv\",\n",
        "          padding=\"same\")(INPUT)\n",
        "    x = layers.ReLU(name =  NAME + \"_relu\")(x)\n",
        "    x = layers.BatchNormalization(name =  NAME + \"_batch_norm\")(x)\n",
        "    x = layers.Dropout(DROP_RATE, name =  NAME + \"_dropout\")(x, training=True)\n",
        "    return x\n",
        "\n",
        "def Convolution(SENSOR_NUM_FILTER, SENSOR_FEAT_FILTER_SIZE, INPUT, NAME):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Convolutional block.\n",
        "\n",
        "    Args:\n",
        "        SENSOR_NUM_FILTER: The number of filters in the Convolutional block.\n",
        "        SENSOR_FEAT_FILTER_SIZE: The filter size of the Convolutional block.\n",
        "        DROP_RATE: The dropout rate for the Convolutional block.\n",
        "        INPUT: The input to the Convolutional block.\n",
        "        NAME: The name of the Convolutional block.\n",
        "\n",
        "    Returns:\n",
        "        x: The output of the Convolutional block.\n",
        "    \"\"\"\n",
        "    x = layers.Conv1D(\n",
        "          SENSOR_NUM_FILTER,\n",
        "          SENSOR_FEAT_FILTER_SIZE,\n",
        "          use_bias=False,\n",
        "          name =  NAME +\"_conv\",\n",
        "          padding=\"same\")(INPUT)\n",
        "    x = layers.ReLU(name =  NAME + \"_relu\")(x)\n",
        "    x = layers.BatchNormalization(name =  NAME + \"_batch_norm\")(x)\n",
        "    return x\n",
        "\n",
        "def LSTM_LayerNorm(NUM_UNITS, lstm_do, return_seq, INPUT, NAME):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Recurrent block.\n",
        "\n",
        "    Args:\n",
        "        NUM_UNITS: The number of LSTM units.\n",
        "        lstm_do: The dropout rate for the LSTM block.\n",
        "        return_seq: Boolean whether to return sequence or not.\n",
        "        INPUT: The input to the Recurrent block.\n",
        "        NAME: The name of the Recurrent block.\n",
        "\n",
        "    Returns:\n",
        "        dist: A Normal distribution.\n",
        "    \"\"\"\n",
        "    x = layers.Bidirectional(layers.LSTM(NUM_UNITS, dropout=lstm_do,                          \n",
        "        time_major=False,return_sequences=return_seq, \n",
        "        name =  NAME + \"_lstm\"), name=NAME + \"_bidirectional\")(INPUT, \n",
        "                                                               training=True)\n",
        "    x = layers.LayerNormalization(name =  NAME + \"_layer_norm\")(x)\n",
        "    return x\n",
        "\n",
        "def Prediction(DROP_RATE, NAME, INPUT):\n",
        "    \"\"\"\n",
        "    Keras DeepPulse Prediction module.\n",
        "\n",
        "    Args:\n",
        "        INPUT: The input to the prediction module.\n",
        "\n",
        "    Returns:\n",
        "        dist: A Normal distribution.\n",
        "    \"\"\"\n",
        "    #x = layers.Dropout(DROP_RATE, name =  NAME + \"_dropout\")(INPUT, training=True)\n",
        "    params = layers.Dense(2, name=\"Dense_1\")(INPUT)\n",
        "    dist = tfp.layers.DistributionLambda(normal_sp, name=\n",
        "                                         \"Distribution_1\")(params)\n",
        "    return dist\n",
        "\n",
        "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
        "    \"\"\"\n",
        "    Creates a bandpass Butterworth IIR filter.\n",
        "    Taken from:\n",
        "    scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
        "\n",
        "    Args:\n",
        "        lowcut: The lower cutoff frequency.\n",
        "        highcut: The higher cutoff frequency.\n",
        "        fs: The sample rate.\n",
        "        order: The order of the filter.\n",
        "\n",
        "    Returns:\n",
        "        b: Numerator polynomial of the IIR filter.\n",
        "        a: Denominator polynomial of the IIR filter.\n",
        "    \"\"\"\n",
        "    nyq = 0.5 * fs\n",
        "    low = lowcut / nyq\n",
        "    high = highcut / nyq\n",
        "    b, a = sci_sig.butter(order, [low, high], btype='band')\n",
        "    return b, a\n",
        "\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    \"\"\"\n",
        "    Applies the bandpass Butterworth IIR filter to the data.\n",
        "    Taken from:\n",
        "    scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
        "\n",
        "    Args:\n",
        "        data: The signal to filter.\n",
        "        lowcut: The lower cutoff frequency.\n",
        "        highcut: The higher cutoff frequency.\n",
        "        fs: The sample rate.\n",
        "        order: The order of the filter.\n",
        "\n",
        "    Returns:\n",
        "        y: The output of the digital filter.\n",
        "    \"\"\"\n",
        "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
        "    y = sci_sig.lfilter(b, a, data)\n",
        "    return y\n",
        "\n",
        "def resample_signal(signal_data, curr_fs, new_fs):\n",
        "    \"\"\"\n",
        "    Resample the signal to a different sample rate.\n",
        "\n",
        "    Args:\n",
        "        signal_data: The signal to resample.\n",
        "        curr_fs: The current sampling frequency.\n",
        "        new_fs: The desired sampling frequency.\n",
        "\n",
        "    Returns:\n",
        "        resampled_signal: The output of the resampling\n",
        "    \"\"\"\n",
        "    num_secs_in_signal = len(signal_data) / curr_fs\n",
        "    num_samples_to_resample = round(num_secs_in_signal * new_fs)\n",
        "    resampled_signal = sci_sig.resample(signal_data, num_samples_to_resample)\n",
        "    return resampled_signal\n",
        "\n",
        "def slidingWindow(sequence, winSize, step=1):\n",
        "    \"\"\"\n",
        "    Creates a sliding window generator to iterate through input sequence.\n",
        "    Taken from: https://stackoverflow.com/a/9878083\n",
        "\n",
        "    Args:\n",
        "        sequence: The signal to window.\n",
        "        winSize: The size of sliding window.\n",
        "        step: The size of overlap between windows.\n",
        "\n",
        "    Returns:\n",
        "        sequence[i:i+winSize]: sliding window generator\n",
        "    \"\"\"\n",
        "    num_of_chunks = ((len(sequence) - winSize) / step) + 1\n",
        "    for i in range(0, int(num_of_chunks) * step, step):\n",
        "        yield sequence[i:i + winSize]\n",
        "\n",
        "def preprocess(signal_data, fs, band_pass_low, band_pass_high, band_pass_order,\n",
        "               resample_fs):\n",
        "    \"\"\"\n",
        "    Preprocesses the signals: performs bandpass filtering then resampling.\n",
        "\n",
        "    Args:\n",
        "        signal_data: The raw signal.\n",
        "        fs: The original sample rate of the signal.\n",
        "        band_pass_low: The lower cutoff frequency of the bandpass filter.\n",
        "        band_pass_high: The higher cutoff frequency of the bandpass filter.\n",
        "        band_pass_order: The order of the bandpass filter.\n",
        "        resample_fs: The desired sampling frequency.\n",
        "\n",
        "    Returns:\n",
        "        filtered_signal_resample: The preprocessed signal.\n",
        "    \"\"\"\n",
        "    filtered_signal = butter_bandpass_filter(signal_data, band_pass_low, \n",
        "                                             band_pass_high, fs, \n",
        "                                             order=band_pass_order)\n",
        "    filtered_signal_resample = resample_signal(filtered_signal, fs, resample_fs)\n",
        "    return filtered_signal_resample\n",
        "\n",
        "def flatten_list(t):\n",
        "    \"\"\"\n",
        "    Flattens a 2D list to a 1D list.\n",
        "\n",
        "    Args:\n",
        "        t: The 2D List.\n",
        "\n",
        "    Returns:\n",
        "        a 1D list.\n",
        "    \"\"\"\n",
        "    return [item for sublist in t for item in sublist]\n",
        "\n",
        "def split_list(alist, wanted_parts=1):\n",
        "    \"\"\"\n",
        "    Splits a list into n lists.\n",
        "    taken from: https://stackoverflow.com/a/752562\n",
        "    Args:\n",
        "        alist: A list to be split.\n",
        "        wanted_parts: The number of splits.\n",
        "\n",
        "    Returns:\n",
        "        list: A N-D list where n = wanted_parts\n",
        "    \"\"\"\n",
        "    length = len(alist)\n",
        "    return [alist[i * length // wanted_parts: (i + 1) * length // \n",
        "                  wanted_parts] for i in range(wanted_parts)]\n",
        "\n",
        "def preprocess_dataset(dataset, band_pass_low, band_pass_high, band_pass_order, \n",
        "                       resample_fs):\n",
        "    \"\"\"\n",
        "    Preprocesses the dataset of signals.\n",
        "\n",
        "    Args:\n",
        "        dataset: The dataset of raw signals.\n",
        "        band_pass_low: The lower cutoff frequency of the bandpass filter.\n",
        "        band_pass_high: The higher cutoff frequency of the bandpass filter.\n",
        "        band_pass_order: The order of the bandpass filter.\n",
        "        resample_fs: The desired sampling frequency.\n",
        "\n",
        "    Returns:\n",
        "        df: A Dataframe containing the preprocessed signals along with \n",
        "            additional information.\n",
        "    \"\"\"\n",
        "    list_of_windows = []\n",
        "    # get sample rates of signals\n",
        "    fs_dataset_PPG = dataset[0][\"PPG_fs\"]\n",
        "    fs_dataset_ACC = dataset[0][\"ACC_fs\"]\n",
        "    # go through each session\n",
        "    for idx, subject in tqdm_notebook(enumerate(range(len(dataset))), \n",
        "                                      desc='Sessions: ', total=len(dataset)):\n",
        "        ppg1_signal_windowed = []\n",
        "        accx_signal_windowed = []\n",
        "        accy_signal_windowed = []\n",
        "        accz_signal_windowed = []\n",
        "        # ---------------PPG------------------------------------------\n",
        "        # preprocess the PPG signal - filter, resample and window\n",
        "        ppg_signal = preprocess(dataset[subject][\"Raw_PPG_1\"], fs_dataset_PPG, \n",
        "                                band_pass_low, band_pass_high, band_pass_order, \n",
        "                                resample_fs)\n",
        "        for i in slidingWindow(ppg_signal, 8 * resample_fs, 2 * resample_fs):\n",
        "            # for each window perform z-norm\n",
        "            # applied on each window to prevent data leakage\n",
        "            i = stats.zscore(i)\n",
        "            ppg1_signal_windowed.append(i)\n",
        "        # ---------------ACC------------------------------------------\n",
        "        # preprocess the ACC signals - filter, resample and window\n",
        "        accx_signal = preprocess(dataset[subject][\"Raw ACC_X\"], fs_dataset_ACC, \n",
        "                                 band_pass_low, band_pass_high, band_pass_order, \n",
        "                                 resample_fs)\n",
        "        for i in slidingWindow(accx_signal, 8 * resample_fs, 2 * resample_fs):\n",
        "            i = stats.zscore(i)\n",
        "            accx_signal_windowed.append(i)\n",
        "        accy_signal = preprocess(dataset[subject][\"Raw ACC_Y\"], fs_dataset_ACC,\n",
        "                                 band_pass_low,band_pass_high, band_pass_order, \n",
        "                                 resample_fs)\n",
        "        for i in slidingWindow(accy_signal, 8 * resample_fs, 2 * resample_fs):\n",
        "            i = stats.zscore(i)\n",
        "            accy_signal_windowed.append(i)\n",
        "        accz_signal = preprocess(dataset[subject][\"Raw ACC_Z\"], fs_dataset_ACC, \n",
        "                                 band_pass_low,band_pass_high, band_pass_order,\n",
        "                                 resample_fs)\n",
        "        for i in slidingWindow(accz_signal, 8 * resample_fs, 2 * resample_fs):\n",
        "            i = stats.zscore(i)\n",
        "            accz_signal_windowed.append(i)\n",
        "        # convert the lists to np.arrays\n",
        "        ppg1_signal_windowed = np.array(ppg1_signal_windowed)\n",
        "        accx_signal_windowed = np.array(accx_signal_windowed)\n",
        "        accy_signal_windowed = np.array(accy_signal_windowed)\n",
        "        accz_signal_windowed = np.array(accz_signal_windowed)\n",
        "        # stack the ACC arrays into a tensor with shape\n",
        "        # (Num of windows, length of windows, 3)\n",
        "        acc_signals_stacked = np.stack((accx_signal_windowed,\n",
        "                                        accy_signal_windowed, \n",
        "                                        accz_signal_windowed), axis=2)\n",
        "        # Expand the dimension of the PPG tensor to have shape\n",
        "        # (Num of windows, length of windows, 1)\n",
        "        ppg1_signal_windowed = np.expand_dims(ppg1_signal_windowed, axis=2)\n",
        "        # go thru each window and make a dict containing all the requried info.\n",
        "        for window in range(len(ppg1_signal_windowed)):\n",
        "            dict_entry = {\n",
        "                \"Signal_ID\": idx,\n",
        "                \"Subject\": dataset[subject][\"Subject\"],\n",
        "                \"Window_ID\": window,\n",
        "                \"PPG\": ppg1_signal_windowed[window],\n",
        "                \"ACC\": acc_signals_stacked[window],\n",
        "                \"SNR\": dataset[subject][\"SNR\"][window],\n",
        "                \"Activity\": dataset[subject][\"Protocol\"][window],\n",
        "                \"Truth\": dataset[subject][\"truth_values\"][window]\n",
        "            }\n",
        "            list_of_windows.append(dict_entry)\n",
        "    # turn the list of dicts to a DF.\n",
        "    df = pd.DataFrame(list_of_windows)\n",
        "    return df\n",
        "\n",
        "def get_test_results(model, df_test, fold, model_name, num_samples):\n",
        "    \"\"\"\n",
        "    Get the results from the unseen session data.\n",
        "\n",
        "    Args:\n",
        "        model: The deep learning model.\n",
        "        df_test: The dataframe of the unseen session data.\n",
        "        fold: The fold of the LOSO CV.\n",
        "        model_name: The name of the model.\n",
        "        num_samples: The number of samples from the predictive distribution.\n",
        "\n",
        "    Returns:\n",
        "        df_calibration: A Dataframe containing the calibration metrics.\n",
        "        df_uncertainty: A Dataframe containing the uncertainty metrics.\n",
        "\n",
        "    \"\"\"\n",
        "    result_dict = []\n",
        "    # create instance of model with the last layer of the model removed\n",
        "    model_deeppulse = keras.Model(inputs=model.input, outputs=\n",
        "                                  model.layers[-2].output)\n",
        "    # for each window\n",
        "    for index, row in tqdm_notebook(df_test.iterrows(), desc='Windows', \n",
        "                                    total=df_test.shape[0]):\n",
        "        # repeat num_samples times to get samples from predictive distribution\n",
        "        for d in range(num_samples):\n",
        "            # get the model output\n",
        "            x = model_deeppulse.predict([np.expand_dims(row[\"PPG\"], axis=0), \n",
        "                                         np.expand_dims(row[\"ACC\"], axis=0)],\n",
        "                                        verbose=0)\n",
        "            for i in x:\n",
        "                distribution_params = []\n",
        "                for item in i:\n",
        "                    distribution_params.append(float(item))\n",
        "            # convert model output to distribution\n",
        "            distri = normal_sp_predict(distribution_params)\n",
        "            # put info into dict to analyse\n",
        "            dicts = {'Signal_ID': row[\"Signal_ID\"],\n",
        "                     'Subject': row[\"Subject\"],\n",
        "                     'Window': row[\"Window_ID\"],\n",
        "                     'SNR': row[\"SNR\"],\n",
        "                     'Activity': row[\"Activity\"],\n",
        "                     'Truth': row[\"Truth\"],\n",
        "                     'Model_ID': fold,\n",
        "                     'Ensemble_ID': d,\n",
        "                     'Mean_Value': distri.mean().numpy(),\n",
        "                     'STD_Value': distri.stddev().numpy()}\n",
        "            result_dict.append(dicts)\n",
        "    # create DF from list of dicts\n",
        "    df_calibration = pd.DataFrame(result_dict)\n",
        "    # save df as csv\n",
        "    file_name = model_name[:-3] + str(\"results_cali.csv\")\n",
        "    df_calibration.to_csv(file_name, index=False)\n",
        "    # compute mean predicted value for each window\n",
        "    groupby_mean_predict = df_calibration.groupby([\"Signal_ID\", \"Subject\", \n",
        "                                                   \"Window\", \"Activity\",\n",
        "                                                   \"SNR\", \"Truth\"], \n",
        "                                            as_index=False)[\"Mean_Value\"].mean()\n",
        "    groupby_mean_predict[\"Absolute Error\"] = abs(groupby_mean_predict[\"Truth\"]\n",
        "                                          - groupby_mean_predict[\"Mean_Value\"])\n",
        "    # compute Epistemic uncertainty\n",
        "    groupby_epistemic = df_calibration.groupby([\"Signal_ID\", \"Subject\", \n",
        "                                                \"Window\"])['Mean_Value'].var() \\\n",
        "        .reset_index(name=\"Epistemic\")\n",
        "    epistemic_column = groupby_epistemic[\"Epistemic\"]\n",
        "    df_uncertainty = pd.concat([groupby_mean_predict, epistemic_column], axis=1)\n",
        "    # compute Aleotoric uncertainty\n",
        "    groupby_aleotoric = df_calibration.groupby([\"Signal_ID\", \"Subject\", \n",
        "                                              \"Window\"])['STD_Value'].median() \\\n",
        "        .reset_index(name=\"Aleotoric\")\n",
        "    aleotoric_column = groupby_aleotoric[\"Aleotoric\"]\n",
        "    df_uncertainty = pd.concat([df_uncertainty, aleotoric_column], axis=1)\n",
        "    # compute predictive uncertainty\n",
        "    df_uncertainty[\"Predictive\"] = df_uncertainty[\"Epistemic\"] + df_uncertainty[\"Aleotoric\"]\n",
        "    df_uncertainty.rename(columns={'Mean_Value': 'Predictive_Mean'}, inplace=True)\n",
        "    # save df as csv\n",
        "    file_name = model_name[:-3] + str(\"results_uncert.csv\")\n",
        "    df_uncertainty.to_csv(file_name, index=False)\n",
        "    return df_calibration, df_uncertainty\n",
        "\n",
        "def get_percentage_overlap_of_fold_sets(list_of_windows):\n",
        "    \"\"\"\n",
        "    Get the percentage overlap of the set of data used for each fold, i.e. the training set/ the val set.\n",
        "    \"percentage\" take from: https://stackoverflow.com/a/29929179\n",
        "\n",
        "    Args:\n",
        "        list_of_windows: A list of lists containing all the windows in the set of data used for each fold.\n",
        "\n",
        "    Returns:\n",
        "        data: A Dataframe containing the percentage overlap for each fold.\n",
        "        matrix: The upper triangle of the Dataframe.\n",
        "\n",
        "    \"\"\"\n",
        "    dict_of_percentages = []\n",
        "    # get all possible combinations of fold into a list of tuples\n",
        "    x = list(itertools.product(range(len(list_of_windows)), repeat=2))\n",
        "    # for each tuple\n",
        "    for i in range(len(x)):\n",
        "        # split the lists into a list for each fold in the tuple\n",
        "        first_list = x[i][0]\n",
        "        second_list = x[i][1]\n",
        "        # compute percentage overlap between the two lists\n",
        "        percentage = len(set(list_of_windows[first_list]) & set(list_of_windows[second_list])) / \\\n",
        "                     float(len(set(list_of_windows[first_list]) | set(list_of_windows[second_list]))) * 100\n",
        "        # store result in dict\n",
        "        result = {\n",
        "            \"Fold X\": first_list,\n",
        "            \"Fold Y\": second_list,\n",
        "            \"percentage\": percentage\n",
        "        }\n",
        "        dict_of_percentages.append(result)\n",
        "    # store in df\n",
        "    df = pd.DataFrame(dict_of_percentages)\n",
        "    data = df.pivot(\"Fold X\", \"Fold Y\", \"percentage\")\n",
        "    # The upper triangle of the data\n",
        "    matrix = np.triu(data)\n",
        "    return data, matrix\n",
        "\n",
        "def get_dataset_splits_loso(DATASET, stratified, test_sze, test_subject):\n",
        "    \"\"\"\n",
        "    Get the train, validation and test sets for the current fold\n",
        "\n",
        "    Args:\n",
        "        DATASET: The dataframe of all windows.\n",
        "        stratified: Whether the train/val sets are stratified on activity type.\n",
        "        test_sze: The percentage of the data used for validation set.\n",
        "        test_subject: The session ID for the test set.\n",
        "\n",
        "    Returns:\n",
        "        df_train: A Dataframe containing the training data.\n",
        "        df_val: A Dataframe containing the validation data.\n",
        "        df_test: A Dataframe containing the test data.\n",
        "\n",
        "    \"\"\"\n",
        "    # get the windows that are associated with the test subject\n",
        "    df_test = shuffle(DATASET.loc[DATASET['Signal_ID'] == test_subject])\n",
        "    # get the train + val sets either stratified or not\n",
        "    if stratified:\n",
        "        df_train, df_val = train_test_split(DATASET, test_size=test_sze, shuffle=True, stratify=DATASET['Activity'])\n",
        "    else:\n",
        "        df_train, df_val = train_test_split(DATASET, test_size=test_sze, shuffle=True)\n",
        "    return df_train, df_val, df_test\n",
        "\n",
        "\n",
        "def display_training_performance(df_result, history, eval_history, fold, path, display, publication):\n",
        "    \"\"\"\n",
        "    Display the training performance of the model on the fold of data.\n",
        "\n",
        "    Args:\n",
        "        df_result: The dataframe of all windows with labels of the set name (i.e. train set).\n",
        "        history: The training history dict.\n",
        "        eval_history: The testing history dict.\n",
        "        fold: The current fold of the LOSO CV.\n",
        "        path: The path of the experiment.\n",
        "        display: Whether to display inline during training.\n",
        "        publication: Whether to export as svg or png format.\n",
        "    \"\"\"\n",
        "  \n",
        "    if publication:\n",
        "        fig_format = 'svg'\n",
        "    else:\n",
        "        fig_format = 'png'\n",
        "    fig = plt.figure(figsize=(40, 25))\n",
        "    my_suptitle = fig.suptitle('Training for Fold ' + str(fold), y=1.05)\n",
        "    gs = GridSpec(nrows=3, ncols=5)\n",
        "    # Bar chart of the size differences of the data splits\n",
        "    ax0 = fig.add_subplot(gs[0, 0])\n",
        "    ax0.title.set_text(\"Size of Dataset Splits\")\n",
        "    sns.countplot(ax=ax0, x=\"Dataset\", data=df_result)\n",
        "    ax0.set_xticklabels(ax0.get_xticklabels(), rotation=0)\n",
        "\n",
        "    # Graph showing the distribution of the truth values for each split of data\n",
        "    ax1 = fig.add_subplot(gs[0, 1])\n",
        "    ax1.title.set_text(\"Distribution of Truth Values\")\n",
        "    sns.kdeplot(x='Truth', fill=False, data=df_result, hue=\"Dataset\", ax=ax1)\n",
        "\n",
        "    # Graph showing the distribution of the Signal to Noise Ratios for each split of data\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    ax2.title.set_text(\"Distribution of Estimated Signal to Noise Ratio\")\n",
        "    sns.kdeplot(x='SNR', fill=False, data=df_result, hue=\"Dataset\", ax=ax2)\n",
        "\n",
        "    # Graph showing the distribution of the Activity Types for each split of data\n",
        "    ax3 = fig.add_subplot(gs[0, 3])\n",
        "    ax3.title.set_text(\"Distribution of Activity Types\")\n",
        "    sns.countplot(x=\"Activity\", hue=\"Dataset\", data=df_result, ax=ax3)\n",
        "    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=75)\n",
        "\n",
        "    # Graph showing the Learning Rate Whilst Training\n",
        "    ax4 = fig.add_subplot(gs[0, 4])\n",
        "    ax4.title.set_text(\"Learning Rate Whilst Training\")\n",
        "    ax4.plot(history.history['lr'])\n",
        "    ax4.set(xlabel=\"Epoch\", ylabel=\"Learning Rate\")\n",
        "\n",
        "    # Graph showing the MAE Learning Curve\n",
        "    ax5 = fig.add_subplot(gs[1, 0:4])\n",
        "    ax5.title.set_text(\"Learning Curve (MAE)\")\n",
        "    ax5.plot(history.history['mae'], label=\"Train\")\n",
        "    ax5.plot(history.history['val_mae'], label=\"Validation\")\n",
        "    ax5.plot([eval_history[1]] * len(history.history['mae']), label=\"Test: \" + str(round(eval_history[1], 3)))\n",
        "    ax5.axvline(x=np.argmin(history.history['val_loss']), color='k', linestyle='--',\n",
        "                label=\"Saved Model @ Epoch: \" + str(np.argmin(history.history['val_loss'])))\n",
        "    ax5.set(xlabel=\"Epoch\", ylabel=\"MAE\")\n",
        "    ax5.legend(loc='upper right')\n",
        "\n",
        "    # Graph showing the NLL Learning Curve\n",
        "    ax6 = fig.add_subplot(gs[2, 0:4])\n",
        "    ax6.title.set_text(\"Learning Curve (NLL)\")\n",
        "    ax6.plot(history.history['loss'], label=\"Train\")\n",
        "    ax6.plot(history.history['val_loss'], label=\"Validation\")\n",
        "    ax6.plot([eval_history[0]] * len(history.history['loss']), label=\"Test: \" + str(round(eval_history[0], 3)))\n",
        "    ax6.axvline(x=np.argmin(history.history['val_loss']), color='k', linestyle='--',\n",
        "                label=\"Saved Model @ Epoch: \" + str(np.argmin(history.history['val_loss'])))\n",
        "    ax6.set_yscale('log')\n",
        "    ax6.set(xlabel=\"Epoch\", ylabel=\"NLL\")\n",
        "    ax6.legend(loc='upper right')\n",
        "\n",
        "    # Bar chart showing the performance of MAE @ model checkpoint\n",
        "    ax7 = fig.add_subplot(gs[1, 4:5])\n",
        "    ax7.title.set_text(\"Performance of Learning (MAE)\")\n",
        "    name = [\"Train\", \"Validate\", \"Test\"]\n",
        "    lii = [history.history['mae'][np.argmin(history.history['val_loss'])],\n",
        "           history.history['val_mae'][np.argmin(history.history['val_loss'])], round(eval_history[1], 3)]\n",
        "    sns.barplot(ax=ax7, x=name, y=lii)\n",
        "    ax7.set(xlabel=\"Performance @ \" + str(np.argmin(history.history['val_loss'])), ylabel=\"MAE\")\n",
        "    \n",
        "    # Bar chart showing the performance of NLL @ model checkpoint\n",
        "    ax8 = fig.add_subplot(gs[2, 4:5])\n",
        "    ax8.title.set_text(\"Performance of Learning (NLL)\")\n",
        "    name = [\"Train\", \"Validate\", \"Test\"]\n",
        "    lii = [history.history['loss'][np.argmin(history.history['val_loss'])],\n",
        "           history.history['val_loss'][np.argmin(history.history['val_loss'])], round(eval_history[0], 3)]\n",
        "    sns.barplot(ax=ax8, x=name, y=lii)\n",
        "    ax8.set(xlabel=\"Performance @ Epoch\" + str(np.argmin(history.history['val_loss'])), ylabel=\"NLL\")\n",
        "    \n",
        "    gs.tight_layout(fig)\n",
        "    # either save file as svg or png\n",
        "    fig_name = path + '/fold' + str(fold) + 'training.' + fig_format\n",
        "    fig.savefig(fig_name, format=fig_format, dpi=fig.dpi,\n",
        "                bbox_inches='tight', bbox_extra_artists=[my_suptitle])\n",
        "    # display graph during execution or not\n",
        "    if display:\n",
        "        plt.show()\n",
        "        time.sleep(10)\n",
        "        plt.close(fig)\n",
        "        output.clear()\n",
        "\n",
        "def display_training_performance_concrete(df_result, history, eval_history, fold, path, model, display, publication):\n",
        "    \"\"\"\n",
        "    Display the training performance of the model on the fold of data using concrete dropout.\n",
        "\n",
        "    Args:\n",
        "        df_result: The dataframe of all windows with labels of the set name (i.e. train set).\n",
        "        history: The training history dict.\n",
        "        eval_history: The testing history dict.\n",
        "        fold: The current fold of the LOSO CV.\n",
        "        path: The path of the experiment.\n",
        "        model: The trained model for that fold.\n",
        "        display: Whether to display inline during training.\n",
        "        publication: Whether to export as svg or png format.\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(40, 25))\n",
        "    my_suptitle = fig.suptitle('Training for Fold ' + str(fold), y=1.05)\n",
        "    gs = GridSpec(nrows=4, ncols=5)\n",
        "    # Bar chart of the size differences of the data splits\n",
        "    ax0 = fig.add_subplot(gs[0, 0])\n",
        "    ax0.title.set_text(\"Size of Dataset Splits\")\n",
        "    sns.countplot(ax=ax0, x=\"Dataset\", data=df_result)\n",
        "    ax0.set_xticklabels(ax0.get_xticklabels(), rotation=0)\n",
        "    # Graph showing the distribution of the truth values for each split of data\n",
        "    ax1 = fig.add_subplot(gs[0, 1])\n",
        "    ax1.title.set_text(\"Distribution of Truth Values\")\n",
        "    sns.kdeplot(x='Truth', fill=False, data=df_result, hue=\"Dataset\", ax=ax1)\n",
        "    #Graph showing the distribution of the Signal to Noise Ratios for each split of data\n",
        "    ax2 = fig.add_subplot(gs[0, 2])\n",
        "    ax2.title.set_text(\"Distribution of Estimated Signal to Noise Ratio\")\n",
        "    sns.kdeplot(x='SNR', fill=False, data=df_result, hue=\"Dataset\", ax=ax2)\n",
        "    # Graph showing the distribution of the Activity Types for each split of data\n",
        "    ax3 = fig.add_subplot(gs[0, 3])\n",
        "    ax3.title.set_text(\"Distribution of Activity Types\")\n",
        "    sns.countplot(x=\"Activity\", hue=\"Dataset\", data=df_result, ax=ax3)\n",
        "    ax3.set_xticklabels(ax3.get_xticklabels(), rotation=75)\n",
        "    #Graph showing the Learning Rate Whilst Training\n",
        "    ax4 = fig.add_subplot(gs[0, 4])\n",
        "    ax4.title.set_text(\"Learning Rate Whilst Training\")\n",
        "    ax4.plot(history.history['lr'])\n",
        "    ax4.set(xlabel=\"Epoch\", ylabel=\"Learning Rate\")\n",
        "    #Graph showing the MAE Learning Curve\n",
        "    ax5 = fig.add_subplot(gs[1, 0:4])\n",
        "    ax5.title.set_text(\"Learning Curve (MAE)\")\n",
        "    ax5.plot(history.history['mae'], label=\"Train\")\n",
        "    ax5.plot(history.history['val_mae'], label=\"Validation\")\n",
        "    ax5.plot([eval_history[1]] * len(history.history['mae']), label=\"Test: \" + str(round(eval_history[1], 3)))\n",
        "    ax5.axvline(x=np.argmin(history.history['val_loss']), color='k', linestyle='--',\n",
        "                label=\"Saved Model @ Epoch: \" + str(np.argmin(history.history['val_loss'])))\n",
        "    ax5.set(xlabel=\"Epoch\", ylabel=\"MAE\")\n",
        "    ax5.legend(loc='upper right')\n",
        "    #Graph showing the NLL Learning Curve\n",
        "    ax6 = fig.add_subplot(gs[2, 0:4])\n",
        "    ax6.title.set_text(\"Learning Curve (NLL)\")\n",
        "    ax6.plot(history.history['loss'], label=\"Train\")\n",
        "    ax6.plot(history.history['val_loss'], label=\"Validation\")\n",
        "    ax6.plot([eval_history[0]] * len(history.history['loss']), label=\"Test: \" + str(round(eval_history[0], 3)))\n",
        "    ax6.axvline(x=np.argmin(history.history['val_loss']), color='k', linestyle='--',\n",
        "                label=\"Saved Model @ Epoch: \" + str(np.argmin(history.history['val_loss'])))\n",
        "    ax6.set_yscale('log')\n",
        "    ax6.set(xlabel=\"Epoch\", ylabel=\"NLL\")\n",
        "    ax6.legend(loc='upper right')\n",
        "    # Bar chart showing the performance of MAE @ model checkpoint\n",
        "    ax7 = fig.add_subplot(gs[1, 4:5])\n",
        "    ax7.title.set_text(\"Performance of Learning (MAE)\")\n",
        "    name = [\"Train\", \"Validate\", \"Test\"]\n",
        "    lii = [history.history['mae'][np.argmin(history.history['val_loss'])],\n",
        "           history.history['val_mae'][np.argmin(history.history['val_loss'])], round(eval_history[1], 3)]\n",
        "    sns.barplot(ax=ax7, x=name, y=lii)\n",
        "    ax7.set(xlabel=\"Performance @ \" + str(np.argmin(history.history['val_loss'])), ylabel=\"MAE\")\n",
        "    # Bar chart showing the performance of NLL @ model checkpoint\n",
        "    ax8 = fig.add_subplot(gs[2, 4:5])\n",
        "    ax8.title.set_text(\"Performance of Learning (NLL)\")\n",
        "    name = [\"Train\", \"Validate\", \"Test\"]\n",
        "    lii = [history.history['loss'][np.argmin(history.history['val_loss'])],\n",
        "           history.history['val_loss'][np.argmin(history.history['val_loss'])], round(eval_history[0], 3)]\n",
        "    sns.barplot(ax=ax8, x=name, y=lii)\n",
        "    ax8.set(xlabel=\"Performance @ Epoch\" + str(np.argmin(history.history['val_loss'])), ylabel=\"NLL\")\n",
        "    #Graph showing the Dropout Learning Curve\n",
        "    ax9 = fig.add_subplot(gs[3, 0:4])\n",
        "    ax9.title.set_text(\"Learning Curve (Dropout)\")\n",
        "    drop_name = np.array([layer.name for layer in model.layers if hasattr(layer, 'p_logit')])\n",
        "    for idx, do in enumerate(drop_name):\n",
        "        ax9.plot(history.history[do], label=str(do))\n",
        "    ax9.axvline(x=np.argmin(history.history['val_loss']), color='k', linestyle='--',\n",
        "                label=\"Saved Model @ Epoch: \" + str(np.argmin(history.history['val_loss'])))\n",
        "    ax9.set(xlabel=\"Epoch\", ylabel=\"Drop Rate\")\n",
        "    ax9.legend(loc='upper right')\n",
        "    # Bar chart showing the learnt dropout rates @ model checkpoint\n",
        "    ax10 = fig.add_subplot(gs[3, 4:5])\n",
        "    ax10.title.set_text(\"Dropout Rate Learnt for Each Layer\")\n",
        "    p_logits = np.array([K.eval(layer.p_logit) for layer in model.layers if hasattr(layer, 'p_logit')])\n",
        "    sns.barplot(\n",
        "        x=drop_name,\n",
        "        y=flatten_list(tf.nn.sigmoid(p_logits).numpy()),\n",
        "        ax=ax10)\n",
        "    ax10.set(xlabel=\"Layer Name\", ylabel=\"Drop Rate\")\n",
        "    ax10.set_xticklabels(ax10.get_xticklabels(), rotation=45)\n",
        "\n",
        "    gs.tight_layout(fig)\n",
        "    # either save file as svg or png\n",
        "    if publication:\n",
        "        fig_format = 'svg'\n",
        "    else:\n",
        "        fig_format = 'png'\n",
        "    fig_name = path + '/fold' + str(fold) + 'training.' + fig_format\n",
        "    fig.savefig(fig_name, format=fig_format, dpi=fig.dpi,\n",
        "                bbox_inches='tight', bbox_extra_artists=[my_suptitle])\n",
        "    # display graph during execution or not\n",
        "    if display:\n",
        "        plt.show()\n",
        "        time.sleep(10)\n",
        "        plt.close(fig)\n",
        "        output.clear()\n",
        "\n",
        "def display_calibration_performance(calibration_df, uncert_df, fold, path, display, publication):\n",
        "    \"\"\"\n",
        "    Display the uncertainty & uncertainty calibration performance of the model on the fold of data.\n",
        "\n",
        "    Args:\n",
        "        calibration_df: A Dataframe containing the calibration metrics.\n",
        "        uncert_df: A Dataframe containing the uncertainty metrics.\n",
        "        fold: The current fold of the LOSO CV.\n",
        "        path: The path of the experiment.\n",
        "        display: Whether to display inline during training.\n",
        "        publication: Whether to export as svg or png format.\n",
        "    \"\"\"\n",
        "    # convert df columns to np arrays\n",
        "    y_true = calibration_df['Truth'].to_numpy()\n",
        "    # x = calibration_df['Window'].to_numpy()\n",
        "    y_pred = calibration_df['Mean_Value'].to_numpy()\n",
        "    y_std = calibration_df['STD_Value'].to_numpy()\n",
        "    # Set random seed\n",
        "    np.random.seed(11)\n",
        "    fig = plt.figure(figsize=(40, 40))\n",
        "    my_suptitle = fig.suptitle('Calibration for Fold ' + str(fold), y=1.05)\n",
        "    gs = GridSpec(nrows=3, ncols=3)\n",
        "    # graph showing the predicted values against the truth along with activity type, SNR and both uncertainty metrics\n",
        "    ax010 = fig.add_subplot(gs[0, 0:3])\n",
        "    # get the start indexes of each activity for the session\n",
        "    start_indexes, activity = repeating_values(uncert_df[\"Activity\"])\n",
        "    colours = ['#42d4f4', '#f032e6', '#fabed4', '#469990', '#dcbeff', '#9A6324', '#fffac8',\n",
        "               '#800000', '#aaffc3', '#000075', '#a9a9a9']\n",
        "    # get upper and lower bands of the uncertainty terms for each window\n",
        "    activities = uncert_df[\"Activity\"].unique()\n",
        "    pred = list(uncert_df[\"Predictive_Mean\"])\n",
        "    aleo = list(uncert_df[\"Aleotoric\"])\n",
        "    epi = list(uncert_df[\"Epistemic\"])\n",
        "    lower_aleo = np.array(pred) - np.array(aleo)\n",
        "    upper_aleo = np.array(pred) + np.array(aleo)\n",
        "    lower_epi = np.array(pred) - np.array(epi)\n",
        "    upper_epi = np.array(pred) + np.array(epi)\n",
        "\n",
        "    ax010.plot(range(len(uncert_df[\"Truth\"])), uncert_df[\"Truth\"])\n",
        "    x_ax = np.arange(0, len(uncert_df[\"Predictive_Mean\"]), 1)\n",
        "    # plot Predicted values\n",
        "    ax010.plot(x_ax, uncert_df[\"Predictive_Mean\"], '-', label=\"Predicted\", color='#e6194B')\n",
        "    # plot truth values\n",
        "    ax010.plot(x_ax, uncert_df[\"Truth\"], '-', label=\"Truth\", color='#000000')\n",
        "    ax020 = ax010.twinx()\n",
        "    # plot SNR values\n",
        "    ax020.plot(x_ax, uncert_df[\"SNR\"], '-', label=\"Est. SNR\", color='#3cb44b')\n",
        "    # plot activity type\n",
        "    for idx, act in enumerate(activity):\n",
        "        if idx + 1 == len(activity):\n",
        "            ax010.axvspan(start_indexes[idx], len(uncert_df[\"Truth\"]),\n",
        "                          color=colours[int(np.where(act == activities)[0])],\n",
        "                          alpha=0.1, label=activities[int(np.where(act == activities)[0])])\n",
        "        else:\n",
        "            ax010.axvspan(start_indexes[idx], start_indexes[idx + 1],\n",
        "                          color=colours[int(np.where(act == activities)[0])],\n",
        "                          alpha=0.1, label=activities[int(np.where(act == activities)[0])])\n",
        "    # plot Aleotoric Uncertainty\n",
        "    ax010.fill_between(x_ax, lower_aleo, upper_aleo,\n",
        "                       color='#4363d8', alpha=0.5, label=\"Aleotoric Uncertainty\")\n",
        "    # plot Epistemic Uncertainty\n",
        "    ax010.fill_between(x_ax, lower_epi, upper_epi,\n",
        "                       color='#f58231', alpha=0.5, label=\"Epistemic Uncertainty\")\n",
        "\n",
        "    lines, labels = ax010.get_legend_handles_labels()\n",
        "    lines2, labels2 = ax020.get_legend_handles_labels()\n",
        "    by_label = dict(zip(labels, lines))\n",
        "    by_label.update(zip(labels2, lines2))\n",
        "    ax010.legend(by_label.values(), by_label.keys(), bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
        "                 ncol=4, mode=\"expand\", borderaxespad=0.)\n",
        "    ax010.set_xlabel('Windows')\n",
        "    ax010.set_ylabel('Beats Per Minute')\n",
        "    ax020.set_ylabel('Signal to Noise Ratio (dB)')\n",
        "    # Plot calibration of predictive Uncertainty\n",
        "    ax3 = fig.add_subplot(gs[1, 0])\n",
        "    uct.plot_calibration(y_pred, y_std, y_true, ax=ax3)\n",
        "    # Plot adversarial group calibration of predictive Uncertainty\n",
        "    ax4 = fig.add_subplot(gs[1, 1])\n",
        "    uct.plot_adversarial_group_calibration(y_pred, y_std, y_true, ax=ax4)\n",
        "    # Plot sharpness of predictive Uncertainty\n",
        "    ax5 = fig.add_subplot(gs[1, 2])\n",
        "    uct.plot_sharpness(y_std, ax=ax5)\n",
        "    # Plot boxplots of Epistemic Uncertainty for each activity type\n",
        "    ax6 = fig.add_subplot(gs[2, 0])\n",
        "    sns.boxplot(x='Activity', y='Epistemic', data=uncert_df, showfliers=False, orient='v', ax=ax6)\n",
        "    ax65 = ax6.twinx()\n",
        "    sns.countplot(x='Activity', data=uncert_df, alpha=0.35, ax=ax65)\n",
        "    # Plot boxplots of Aleotoric Uncertainty for each activity type\n",
        "    ax7 = fig.add_subplot(gs[2, 1])\n",
        "    sns.boxplot(x='Activity', y='Aleotoric', data=uncert_df, showfliers=False, orient='v', ax=ax7)\n",
        "    # plot relationship between Epistemic & Aleotoric Uncertainty\n",
        "    ax8 = fig.add_subplot(gs[2, 2])\n",
        "    sns.scatterplot(x='Aleotoric', y='Epistemic', data=uncert_df, ax=ax8)\n",
        "    gs.tight_layout(fig)\n",
        "    # either save file as svg or png\n",
        "    if publication:\n",
        "        fig_format = 'svg'\n",
        "    else:\n",
        "        fig_format = 'png'\n",
        " \n",
        "    fig_plot_name = 'calibration.'    \n",
        "    fig_name = path + '/fold' + str(fold) + fig_plot_name + fig_format\n",
        "    fig.savefig(fig_name, format=fig_format, dpi=fig.dpi, bbox_inches='tight',\n",
        "                bbox_extra_artists=[my_suptitle])\n",
        "    # display graph during execution or not\n",
        "    if display:\n",
        "        plt.show()\n",
        "        time.sleep(10)\n",
        "        plt.close(fig)\n",
        "        output.clear()\n",
        "\n",
        "def display_overall_performance(path, unique_check_train, unique_check_val, \n",
        "                                unique_check_test, display, publication):\n",
        "    \"\"\"\n",
        "    Display the overall performance of the model on all the fold of data.\n",
        "    unique_check_train, unique_check_val, unique_check_test,\n",
        "    Args:\n",
        "        path: The path of the experiment.\n",
        "        unique_check_train: list of list containing all windows used for training for each fold.\n",
        "        unique_check_val: list of list containing all windows used for validation for each fold.\n",
        "        unique_check_test: list of list containing all windows used for testing for each fold.\n",
        "        display: Whether to display inline during training.\n",
        "        publication: Whether to export as svg or png format.\n",
        "    \"\"\"\n",
        "    all_uncert_df, all_calibration_df, df_session_specific, df_overall = get_overall_stats(path)\n",
        "    # get calibration vals to numpy arrays\n",
        "    y_true = all_calibration_df['Truth'].to_numpy()\n",
        "    y_pred = all_calibration_df['Mean_Value'].to_numpy()\n",
        "    y_std = all_calibration_df['STD_Value'].to_numpy()\n",
        "    # Set random seed\n",
        "    np.random.seed(11)\n",
        "    fig = plt.figure(figsize=(50, 50))\n",
        "\n",
        "    my_suptitle = fig.suptitle('Overall Results', y=1.05)\n",
        "    gs = GridSpec(nrows=6, ncols=4)\n",
        "    # Plot MAE for each session \n",
        "    ax001 = fig.add_subplot(gs[0, 0])\n",
        "    all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].mean().plot.bar(ax=ax001)\n",
        "    ax001.axhline(np.mean(all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].mean()), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].mean()),2)) + ' BPM')\n",
        "    ax001.set_ylabel('Mean Absolute Error')\n",
        "    ax001.legend(loc='best')\n",
        "    ax001.set_title(\"Mean Absolute Error By Session\")\n",
        "    # Plot MAX AE for each session\n",
        "    ax002 = fig.add_subplot(gs[0, 1])\n",
        "    all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].max().plot.bar(ax=ax002)\n",
        "    ax002.axhline(np.mean(all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].max()), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(all_uncert_df.groupby(\"Signal_ID\")['Absolute Error'].max()),2)) + ' BPM')\n",
        "    ax002.set_ylabel('Max Absolute Error')\n",
        "    ax002.legend(loc='best')\n",
        "    ax002.set_title(\"Max Absolute Error By Session\")\n",
        "    # Plot MAE for each Activity TYPE\n",
        "    ax003 = fig.add_subplot(gs[0, 2])\n",
        "    all_uncert_df.groupby(\"Activity\")['Absolute Error'].mean().plot.bar(ax=ax003)\n",
        "    ax003.axhline(np.mean(all_uncert_df.groupby(\"Activity\")['Absolute Error'].mean()), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(all_uncert_df.groupby(\"Activity\")['Absolute Error'].mean()),2)) + ' BPM')\n",
        "    ax003.set_ylabel('Mean Absolute Error')\n",
        "    ax003.legend(loc='best')\n",
        "    ax003.set_title(\"Mean Absolute Error By Activity\")\n",
        "    # Plot MAE for each Activity TYPE\n",
        "    ax004 = fig.add_subplot(gs[0, 3])\n",
        "    all_uncert_df.groupby(\"Fold\", sort=False)['Absolute Error'].mean().plot.bar(ax=ax004)\n",
        "    ax004.axhline(np.mean(all_uncert_df.groupby(\"Fold\")['Absolute Error'].mean()), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(all_uncert_df.groupby(\"Fold\")['Absolute Error'].mean()),2)) + ' BPM')\n",
        "    ax004.set_ylabel('Mean Absolute Error')\n",
        "    ax004.legend(loc='best')\n",
        "    ax004.set_title(\"Mean Absolute Error By Fold\")\n",
        "    \n",
        "    # Plot heatmap of overlap between folds for train sets\n",
        "    ax005 = fig.add_subplot(gs[1, 0])\n",
        "    data, matrix = get_percentage_overlap_of_fold_sets(unique_check_train)\n",
        "    sns.heatmap(data, mask=matrix, cmap=\"RdYlBu\", ax=ax005)\n",
        "    ax005.set_title(\"% Overlap Between Training Sets for Each Fold\")\n",
        "    # Plot heatmap of overlap between folds for val sets\n",
        "    ax006 = fig.add_subplot(gs[1, 1])\n",
        "    data, matrix = get_percentage_overlap_of_fold_sets(unique_check_val)\n",
        "    sns.heatmap(data, mask=matrix, cmap=\"RdYlBu\", ax=ax006)\n",
        "    ax006.set_title(\"% Overlap Between Validation Sets for Each Fold\")\n",
        "    # Plot heatmap of overlap between folds for test sets\n",
        "    ax007 = fig.add_subplot(gs[1, 2])\n",
        "    data, matrix = get_percentage_overlap_of_fold_sets(unique_check_test)\n",
        "    sns.heatmap(data, mask=matrix, cmap=\"RdYlBu\", ax=ax007)\n",
        "    ax007.set_title(\"% Overlap Between Test Sets for Each Fold\")\n",
        "    # plot calibration plot\n",
        "    ax007 = fig.add_subplot(gs[1, 3])\n",
        "    avg_len_train_val_test = [average_len(unique_check_train), \n",
        "                              average_len(unique_check_val), \n",
        "                             average_len(unique_check_test)]\n",
        "    avg_len_names = [\"Train\", \"Validation\", \"Test\"]\n",
        "    ax007.bar(avg_len_names,avg_len_train_val_test)\n",
        "    ax007.set_ylabel('Number of Samples')\n",
        "    ax007.set_title('Average Size of Each Data Split')\n",
        "    \n",
        "    ax008 = fig.add_subplot(gs[2, 0])\n",
        "    sns.scatterplot(x='Truth', y='Absolute Error', data=all_uncert_df, ax=ax008)\n",
        "    ax008.set_title('Relationship Between Truth and Absolute Error')\n",
        "    # Plot relationship between SNR and AE\n",
        "    ax009 = fig.add_subplot(gs[2, 1])\n",
        "    sns.scatterplot(x='SNR', y='Absolute Error', data=all_uncert_df, ax=ax009)\n",
        "    ax009.set_title('Relationship Between Est. SNR and Absolute Error')\n",
        "    # Plot relationship between SNR and AE\n",
        "    ax010 = fig.add_subplot(gs[2, 2])\n",
        "    sns.boxplot(x='Activity', y='Absolute Error', data=all_uncert_df, showfliers=False, orient='v', ax=ax010)\n",
        "    ax010.set_title('Relationship Between Activity and Absolute Error')\n",
        "    # Plot bia/var\n",
        "    ax011 = fig.add_subplot(gs[2, 3])\n",
        "    sns.barplot(x='Fold', y='Session_Bias', data=df_session_specific, ax=ax011)\n",
        "    ax011.axhline(np.mean(df_session_specific['Session_Bias']), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(df_session_specific['Session_Bias']),2)) + ' BPM')\n",
        "    ax011.set_xlabel('Fold')\n",
        "    ax011.set_ylabel('Bias')\n",
        "    ax011.set_title('Bias per Fold')\n",
        "    ax011.legend(loc='best')\n",
        "\n",
        "    ax012 = fig.add_subplot(gs[3, 0])\n",
        "    uct.plot_calibration(y_pred, y_std, y_true, ax=ax012)\n",
        "    # plot adversarial group calibration plot\n",
        "    ax013 = fig.add_subplot(gs[3, 1])\n",
        "    uct.plot_adversarial_group_calibration(y_pred, y_std, y_true, ax=ax013)\n",
        "    ax014 = fig.add_subplot(gs[3, 2])\n",
        "    sns.barplot(x='Fold', y='Session_Miscal_Area', data=df_session_specific, ax=ax014)\n",
        "    ax014.axhline(np.mean(df_session_specific['Session_Miscal_Area']), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(df_session_specific['Session_Miscal_Area']),2)) + ' BPM')\n",
        "    ax014.set_xlabel('Fold')\n",
        "    ax014.set_ylabel('Miscalibration Area')\n",
        "    ax014.set_title('Miscalibration Area per Fold')\n",
        "    ax014.legend(loc='best')\n",
        "    \n",
        "    ax015 = fig.add_subplot(gs[3, 3])\n",
        "    sns.barplot(x='Fold', y='Session_Var', data=df_session_specific, ax=ax015)\n",
        "    ax015.axhline(np.mean(df_session_specific['Session_Var']), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(df_session_specific['Session_Var']),2)) + ' BPM')\n",
        "    ax015.set_xlabel('Fold')\n",
        "    ax015.set_ylabel('Variance')\n",
        "    ax015.set_title('Variance per Fold')\n",
        "    ax015.legend(loc='best')\n",
        "    # plot sharpness plot\n",
        "    ax016 = fig.add_subplot(gs[4, 0])\n",
        "    uct.plot_sharpness(y_std, ax=ax016)\n",
        "    ax017 = fig.add_subplot(gs[4, 1])\n",
        "    sns.barplot(x='Fold', y='Session_Sharpness', data=df_session_specific, ax=ax017)\n",
        "    ax017.axhline(np.mean(df_session_specific['Session_Sharpness']), ls='--',\n",
        "                  label=\"Average @\" + str(\n",
        "                      round(np.mean(df_session_specific['Session_Sharpness']),2)) + ' BPM')\n",
        "    ax017.set_xlabel('Fold')\n",
        "    ax017.set_ylabel('Sharpness')\n",
        "    ax017.set_title('Sharpness per Fold')\n",
        "    # plot boxplot of activity type and epistemic uncert\n",
        "    ax018 = fig.add_subplot(gs[4, 2])\n",
        "    sns.boxplot(x='Activity', y='Epistemic', data=all_uncert_df, showfliers=False, orient='v', ax=ax018)\n",
        "    ax0185 = ax018.twinx()\n",
        "    sns.countplot(x='Activity', data=all_uncert_df, alpha=0.5, ax=ax0185)\n",
        "    ax0185.tick_params('x', labelrotation=30)\n",
        "    ax018.set_title('Relationship Between Activity and Epistemic Uncertainty')\n",
        "    # plot boxplot of activity type and Aleotoric uncert\n",
        "    ax019 = fig.add_subplot(gs[4, 3])\n",
        "    sns.boxplot(x='Activity', y='Aleotoric', data=all_uncert_df, showfliers=False, orient='v', ax=ax019)\n",
        "    ax019.tick_params('x', labelrotation=30)\n",
        "    ax019.set_title('Relationship Between Activity and Aleotoric Uncertainty')\n",
        "    # plot relationship between Aleotoric & Epistemic uncert\n",
        "    ax020 = fig.add_subplot(gs[5, 0])\n",
        "    sns.scatterplot(x='SNR', y='Aleotoric', data=all_uncert_df, ax=ax020)\n",
        "    ax020.set_title('Relationship Between Est. SNR and Aleotoric Uncertainty')\n",
        "    ax021 = fig.add_subplot(gs[5, 1])\n",
        "    sns.scatterplot(x='SNR', y='Epistemic', data=all_uncert_df, ax=ax021)\n",
        "    ax021.set_title('Relationship Between Est. SNR and Epistemic Uncertainty')\n",
        "    ax021.set_yscale('log')\n",
        "    ax022 = fig.add_subplot(gs[5, 2])\n",
        "    ax022.set_yscale('log')\n",
        "    sns.scatterplot(x='Aleotoric', y='Epistemic', data=all_uncert_df, ax=ax022)\n",
        "    ax022.set_title('Relationship Between Aleotoric and Epistemic Uncertainty')\n",
        "    \n",
        "    gs.tight_layout(fig)\n",
        "\n",
        "    # either save file as svg or png\n",
        "    if publication:\n",
        "        fig_format = 'svg'\n",
        "    else:\n",
        "        fig_format = 'png'\n",
        "    fig_name = path + '/overall.' + fig_format\n",
        "    fig.savefig(fig_name, format=fig_format, dpi=fig.dpi, bbox_inches='tight',\n",
        "                bbox_extra_artists=[my_suptitle])\n",
        "    # display graph during execution or not\n",
        "    if display:\n",
        "        plt.show()\n",
        "        time.sleep(10)\n",
        "        plt.close(fig)\n",
        "        output.clear()\n",
        "\n",
        "def get_overall_stats(path):\n",
        "    \"\"\"\n",
        "    Gets overall stats of the performance of the model\n",
        "\n",
        "    Args:\n",
        "        path: The path of the experiment.\n",
        "\n",
        "    Returns:\n",
        "        all_uncert_df: Dataframe containing the uncertainty metrics.\n",
        "        all_calibration_df: Dataframe containing the calibration metrics.\n",
        "        df_session_specific: Dataframe containing session/fold specific metrics.\n",
        "        df_overall: Dataframe containing overall metrics to compare with other models.\n",
        "    \"\"\"\n",
        "    # init lists to store metrics\n",
        "    calibration_results = []\n",
        "    fold = []\n",
        "    sess_mae = []\n",
        "    sess_max_ae = []\n",
        "    sess_ma = []\n",
        "    sess_sharp = []\n",
        "    sess_expected_loss = []\n",
        "    sess_bias = []\n",
        "    sess_var = []\n",
        "    cali_filename = '*results_cali.csv'\n",
        "    uncert_filename = '*results_uncert.csv'\n",
        "    sess_spec_file_name = \"results_fold_specific.csv\"\n",
        "    overall_file_name = \"results_overall.csv\"\n",
        "    #get all the fold results into 1 df\n",
        "    for filename in os.listdir(path):\n",
        "        if fnmatch.fnmatch(filename, cali_filename):\n",
        "            calibration_results.append(filename)\n",
        "    dfs = list()\n",
        "    for i, f in enumerate(calibration_results):\n",
        "        data = pd.read_csv(path + \"/\" + f)\n",
        "        #store fold name in df\n",
        "        data['Fold'] = re.findall(r'\\d+', f)[0]\n",
        "        #get metrics for computing calibration metrics\n",
        "        y_true = data['Truth'].to_numpy()\n",
        "        y_pred = data['Mean_Value'].to_numpy()\n",
        "        y_std = data['STD_Value'].to_numpy()\n",
        "        #compute calibration metrics\n",
        "        sess_sharp.append(uct.metrics_calibration.sharpness(y_std))\n",
        "        sess_ma.append(uct.metrics_calibration.miscalibration_area(y_pred, y_std, y_true))\n",
        "        dfs.append(data)\n",
        "    #concat all dfs to one df\n",
        "    all_calibration_df = pd.concat(dfs, ignore_index=True)\n",
        "    # get all calib result files into one df\n",
        "    uncert_results = []\n",
        "    for filename in os.listdir(path):\n",
        "        if fnmatch.fnmatch(filename, uncert_filename):\n",
        "            uncert_results.append(filename)\n",
        "    dfs1 = list()\n",
        "    for i, f in enumerate(uncert_results):\n",
        "        data = pd.read_csv(path + \"/\" + f)\n",
        "        # store fold name in df\n",
        "        data['Fold'] = re.findall(r'\\d+', f)[0]\n",
        "        fold.append(re.findall(r'\\d+', f)[0])\n",
        "        #compute fold specific metrics\n",
        "        sess_mae.append(np.mean(data[\"Absolute Error\"]))\n",
        "        sess_max_ae.append(np.max(data[\"Absolute Error\"]))\n",
        "        all_pred = data[\"Predictive_Mean\"].to_numpy()\n",
        "        y_test = data[\"Truth\"].to_numpy()\n",
        "        #compute bias + variance of folds\n",
        "        main_predictions = np.mean(all_pred, axis=0)\n",
        "        sess_bias.append(np.sum((main_predictions - y_test) ** 2) / y_test.size)\n",
        "        sess_var.append(np.sum((main_predictions - all_pred) ** 2) / all_pred.size)\n",
        "        dfs1.append(data)\n",
        "    # get all uncertainty result files into one df\n",
        "    all_uncert_df = pd.concat(dfs1, ignore_index=True)\n",
        "    #store fold specific metrics in dict to make into df\n",
        "    fold_specific_metrics = []\n",
        "    for i, session in enumerate(fold):\n",
        "      session_metrics = {\n",
        "          \"Fold\": fold[i],\n",
        "          \"Session_MAE\": sess_mae[i],\n",
        "          \"Session_Max_AE\": sess_max_ae[i],\n",
        "          \"Session_Miscal_Area\": sess_ma[i],\n",
        "          \"Session_Sharpness\": sess_sharp[i],\n",
        "          \"Session_Bias\": sess_bias[i],\n",
        "          \"Session_Var\": sess_var[i]\n",
        "      }\n",
        "      fold_specific_metrics.append(session_metrics)\n",
        "    # store overall metrics in dict to make into df\n",
        "    overall_dict = {\n",
        "        \"Exp_Name\": path.split(\"/Exp/\",1)[1],\n",
        "        \"MAE\": np.mean(sess_mae),\n",
        "        \"MAE_std\": np.std(sess_mae),\n",
        "        \"Max_Abs_Error\": np.mean(sess_max_ae),\n",
        "        \"Max_Abs_Error_std\": np.std(sess_max_ae),\n",
        "        \"Miscal_Area\": np.mean(sess_ma),\n",
        "        \"Miscal_Area_std\": np.std(sess_ma),\n",
        "        \"Sharpness\": np.mean(sess_sharp),\n",
        "        \"Sharpness_std\": np.std(sess_sharp),\n",
        "        \"Bias\": np.mean(sess_bias),\n",
        "        \"Bias_std\": np.std(sess_bias),\n",
        "        \"Var\": np.mean(sess_var),\n",
        "        \"Var_std\": np.std(sess_var)\n",
        "    }\n",
        "    #convert list of dicts to df\n",
        "    df_session_specific = pd.DataFrame(fold_specific_metrics)\n",
        "    df_overall = pd.DataFrame([overall_dict])\n",
        "    #save both dfs are csv files\n",
        "    df_session_specific.to_csv(path + \"/\" + str(sess_spec_file_name), index=False)\n",
        "    df_overall.to_csv(path + \"/\" + str(overall_file_name), index=False)\n",
        "    return all_uncert_df, all_calibration_df, df_session_specific, df_overall\n",
        "\n",
        "def save_pickle(PATH, EXP_NAME, Name, pkl_list):\n",
        "    \"\"\"\n",
        "    Save list as pickle.\n",
        "\n",
        "    Args:\n",
        "        PATH: The path of the experiment.\n",
        "        EXP_NAME: The name of the experiment.\n",
        "        Name: The name of the file.\n",
        "        pkl_list: The list to pickle.\n",
        "    \"\"\"\n",
        "    outfile = open(PATH + \"/\" + EXP_NAME + \"/\" + Name, 'wb')\n",
        "    pickle.dump(pkl_list, outfile)\n",
        "    outfile.close()\n",
        "\n",
        "def repeating_values(x):\n",
        "    \"\"\"\n",
        "    Get the results from the unseen session data.\n",
        "\n",
        "    Args:\n",
        "        x: list of activities.\n",
        "\n",
        "    Returns:\n",
        "        start_indexes: list of indices where the activity type starts.\n",
        "        activity: the activity name related to that index.\n",
        "    \"\"\"\n",
        "    start_indexes = []\n",
        "    activity = []\n",
        "    cur_idx = 0\n",
        "    i = 1\n",
        "    while i < len(x):\n",
        "        if x[cur_idx] == x[i]:\n",
        "            start_indexes.append(cur_idx)\n",
        "            activity.append(x[cur_idx])\n",
        "            # Increase value of i up to the index where there is different value\n",
        "            while i < len(x):\n",
        "                if x[cur_idx] != x[i]:\n",
        "                    # Set cur_idx to the index of different value\n",
        "                    cur_idx = i\n",
        "                    i += 1\n",
        "                    break\n",
        "                i += 1\n",
        "        else:\n",
        "            cur_idx = i\n",
        "            i += 1\n",
        "    return start_indexes, activity\n",
        "\n",
        "def Negative_Log_Likelihood(y, distribution):\n",
        "    \"\"\"\n",
        "    Get NLL of an observation given a distribution.\n",
        "\n",
        "    Args:\n",
        "        y: an observation.\n",
        "        distribution: a fitted distribution.\n",
        "\n",
        "    Returns:\n",
        "        -distribution.log_prob(y): the negative log likelihood of y given distribution.\n",
        "    \"\"\"\n",
        "    return -distribution.log_prob(y)\n",
        "\n",
        "def normal_sp(params):\n",
        "    \"\"\"\n",
        "    Converts model outputs to Normal Distribution\n",
        "\n",
        "    Args:\n",
        "        params: list of parameters outputted from model.\n",
        "\n",
        "    Returns:\n",
        "        tfd.Normal: A normal distribution.\n",
        "    \"\"\"\n",
        "    return tfd.Normal(loc=params[:, 0:1], scale=1e-3 + tf.math.softplus(0.05 * params[:, 1:2]))\n",
        "\n",
        "def normal_sp_predict(params):\n",
        "    \"\"\"\n",
        "    Converts model outputs to Normal Distribution\n",
        "\n",
        "    Args:\n",
        "        params: list of parameters outputted from model.\n",
        "\n",
        "    Returns:\n",
        "        tfd.Normal: A normal distribution.\n",
        "    \"\"\"\n",
        "    return tfd.Normal(loc=params[0], scale=1e-3 + tf.math.softplus(0.05 * params[1]))\n",
        "\n",
        "def train_model_LOSO(data, PATH, EXP_NAME, num_epochs, batch_sze, stratified, \n",
        "                     test_sze, num_predict_samples, band_pass_low, band_pass_high, \n",
        "                     band_pass_order, resample_fs, display, publication, \n",
        "                     SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, SENSOR_DROPOUT, \n",
        "                     GLOBAL_FILTER_SIZE, GLOBAL_NUM_FILTER, \n",
        "                     GLOBAL_DROPOUT, RECURRENT_UNITS, \n",
        "                     RECURRENT_DROPOUT, MAXPOOLING):\n",
        "    \"\"\"\n",
        "    Preprocesses data, trains the model, displays training performance, predicts values of unseen session,\n",
        "    displays the performance of uncertainty metrics. Repeats for each fold in dataset then displays overall\n",
        "    performance.\n",
        "\n",
        "    Args:\n",
        "        data: The raw data file.\n",
        "        PATH: The path of the experiment folder.\n",
        "        EXP_NAME: The experiment name.\n",
        "        num_epochs: The number of training epochs.\n",
        "        batch_sze: The batch size of the model.\n",
        "        stratified: Whether the train/val sets are stratified on activity type.\n",
        "        test_sze: The percentage of the data used for validation set.\n",
        "        num_predict_samples: The number of samples from the predictive distribution.\n",
        "        band_pass_low: The lower cutoff frequency of the bandpass filter.\n",
        "        band_pass_high: The higher cutoff frequency of the bandpass filter.\n",
        "        band_pass_order: The order of the bandpass filter.\n",
        "        resample_fs: The desired sampling frequency.\n",
        "        display: Whether to display inline during training.\n",
        "        publication: Whether to export as svg or png format.\n",
        "        SENSOR_FILTER_SIZE: The filter size of the Sensor Specific Convolutional block.\n",
        "        SENSOR_NUM_FILTER: The number of filters in the Sensor Specific Convolutional block.\n",
        "        SENSOR_DROPOUT: The dropout rate for the Sensor Specific Convolutional block.\n",
        "        GLOBAL_FILTER_SIZE: The filter size of the Global Convolutional block.\n",
        "        GLOBAL_NUM_FILTER: The number of filters in the Global Convolutional block.\n",
        "        GLOBAL_DROPOUT: The dropout rate for the Global Convolutional block.\n",
        "        RECURRENT_UNITS: The number of units in the Recurrent block.\n",
        "        RECURRENT_DROPOUT: The dropout rate for the Recurrent block.\n",
        "        MAXPOOLING: The max pooling for the Convolutional blocks.\n",
        "    \"\"\"\n",
        "    # preprocess dataset into df\n",
        "    print(\"Preprocessing Dataset: \")\n",
        "    DATASET = preprocess_dataset(data, band_pass_low, band_pass_high, \n",
        "                                 band_pass_order, resample_fs)\n",
        "    unique_check_train = []\n",
        "    unique_check_val = []\n",
        "    unique_check_test = []\n",
        "    train_times = []\n",
        "    predict_times = []\n",
        "    path = PATH + str(EXP_NAME)\n",
        "    SUBJECT = DATASET[\"Signal_ID\"].unique().tolist()\n",
        "    random.shuffle(SUBJECT, random.random)\n",
        "    model_print = 0\n",
        "    # for each fold in dataset\n",
        "    for fold, test_subject in enumerate(SUBJECT):\n",
        "        model_print += 1\n",
        "        # get train/val/test split\n",
        "        df_train, df_val, df_test = get_dataset_splits_loso(DATASET, stratified, \n",
        "                                                            test_sze, test_subject)\n",
        "\n",
        "        df_train[\"Dataset\"] = \"Train\"\n",
        "        df_val[\"Dataset\"] = \"Validation\"\n",
        "        df_test[\"Dataset\"] = \"Test\"\n",
        "        # get data in correct format for model\n",
        "        PPG_Train = np.stack(df_train['PPG'], axis=0)\n",
        "        ACC_Train = np.stack(df_train['ACC'], axis=0)\n",
        "        Truth_Train = np.stack(df_train['Truth'], axis=0)\n",
        "\n",
        "        PPG_Test = np.stack(df_test['PPG'], axis=0)\n",
        "        ACC_Test = np.stack(df_test['ACC'], axis=0)\n",
        "        Truth_Test = np.stack(df_test['Truth'], axis=0)\n",
        "\n",
        "        PPG_Val = np.stack(df_val['PPG'], axis=0)\n",
        "        ACC_Val = np.stack(df_val['ACC'], axis=0)\n",
        "        Truth_Val = np.stack(df_val['Truth'], axis=0)\n",
        "\n",
        "        # callbacks\n",
        "        es = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=70,\n",
        "                                              verbose=1, restore_best_weights=False)\n",
        "        tqdm_callback = tfa.callbacks.TQDMProgressBar()\n",
        "        modelname = path + '/fold' + str(fold) + '.h5'\n",
        "        rlronp = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n",
        "                                                      factor=0.9, patience=5,\n",
        "                                                      verbose=1)\n",
        "        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "            modelname,\n",
        "            monitor='val_loss',\n",
        "            save_best_only=True,\n",
        "            verbose=1, mode='min')\n",
        "       \n",
        "            # init model & optimiser\n",
        "        model = make_DeepPulse(SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, \n",
        "                               SENSOR_DROPOUT, GLOBAL_FILTER_SIZE, \n",
        "                               GLOBAL_NUM_FILTER, GLOBAL_DROPOUT, \n",
        "                               RECURRENT_UNITS, RECURRENT_DROPOUT, MAXPOOLING)\n",
        "        callbacks = [es, rlronp, checkpoint_callback, tqdm_callback]\n",
        "        OPT = tf.optimizers.Nadam()\n",
        "        model.compile(loss=Negative_Log_Likelihood, optimizer=OPT, metrics=['mae'])\n",
        "        # train model\n",
        "        start_training_time = time.time()\n",
        "        print(\"Fit model on training data fold \", fold, \"/\", len(SUBJECT))\n",
        "        history = model.fit(\n",
        "            [PPG_Train, ACC_Train],\n",
        "            Truth_Train,\n",
        "            batch_size=batch_sze,\n",
        "            epochs=num_epochs,\n",
        "            validation_data=([PPG_Val, ACC_Val], Truth_Val),\n",
        "            verbose=0,\n",
        "            callbacks=callbacks)\n",
        "        time.sleep(2)\n",
        "        output.clear()\n",
        "        # load best performing weights\n",
        "        model.load_weights(modelname)\n",
        "        # use trained model to predict on unseen session\n",
        "        eval_history = model.evaluate(\n",
        "            [PPG_Test, ACC_Test],\n",
        "            Truth_Test,\n",
        "            batch_size=batch_sze, verbose=0,\n",
        "            callbacks=[tqdm_callback])\n",
        "        end_training_time = time.time()\n",
        "        train_time = end_training_time - start_training_time\n",
        "        output.clear()\n",
        "        # store windows used in each set of data to perform similarity analysis\n",
        "        train_set_uiq = list(df_train.Signal_ID.astype(str).str.cat(df_train.Window_ID.astype(str), sep='w'))\n",
        "        val_set_uiq = list(df_val.Signal_ID.astype(str).str.cat(df_val.Window_ID.astype(str), sep='w'))\n",
        "        test_set_uiq = list(df_test.Signal_ID.astype(str).str.cat(df_test.Window_ID.astype(str), sep='w'))\n",
        "        unique_check_train.append(train_set_uiq)\n",
        "        unique_check_val.append(val_set_uiq)\n",
        "        unique_check_test.append(test_set_uiq)\n",
        "        # save model arch image\n",
        "        if model_print == 1:\n",
        "            tf.keras.utils.plot_model(\n",
        "                make_DeepPulse(SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, \n",
        "                               SENSOR_DROPOUT, GLOBAL_FILTER_SIZE, \n",
        "                               GLOBAL_NUM_FILTER, GLOBAL_DROPOUT, \n",
        "                               RECURRENT_UNITS, RECURRENT_DROPOUT, MAXPOOLING),\n",
        "                to_file=path + \"/model.png\",\n",
        "                show_shapes=True,\n",
        "            )\n",
        "            # save experiment specific parameters\n",
        "            with open(path + \"/variables.txt\", \"w\") as f:\n",
        "                f.write(\"PREPROCESSING VARIABLES:\" + \"\\n \\n\" + \"BAND_PASS_LOW = \"\n",
        "                 + str(band_pass_low) + \"\\n\" + \"BAND_PASS_HIGH = \" + \n",
        "                 str(band_pass_high) + \"\\n\" + \"BAND_PASS_ORDER = \" + \n",
        "                 str(band_pass_order) + \"\\n\" + \"RESAMPLE_FS = \" + str(resample_fs)\n",
        "                  + \"TRAINING VARIABLES:\" + \"\\n \\n\"  + \"CV = LOSO \\n\"  + \"NUM_EPOCHS = \" + \n",
        "                  str(num_epochs) + \"\\n\" \n",
        "                + \"BATCH_SIZE = \" + str(batch_sze) + \"\\n\" \n",
        "                + \"STRATIFIED = \" + str(stratified) + \"\\n\" + \"VAL_SET_SIZE = \" \n",
        "                + str(test_sze) + \"\\n\" + \"NUM_PREDICT_SAMPLES = \" + \n",
        "                str(num_predict_samples)+ \"\\n\" + \"ARCHITECTURAL VARIABLES:\" + \n",
        "                \"\\n \\n\" + \"SENSOR_FILTER_SIZE = \" + str(SENSOR_FILTER_SIZE) + \"\\n\" + \n",
        "                \"SENSOR_NUM_FILTER = \" + str(SENSOR_NUM_FILTER) +\n",
        "                 \"\\n\"+ \"SENSOR_DROPOUT = \" \n",
        "                + str(SENSOR_DROPOUT) + \"\\n\"+ \"SENSOR_CONV_TYPE = \" + str(SENSOR_CONV_TYPE) \n",
        "                + \"\\n\" + \"GLOBAL_FILTER_SIZE = \" + str(GLOBAL_FILTER_SIZE)\n",
        "                  + \"\\n\"+ \"GLOBAL_NUM_FILTER = \" + str(GLOBAL_NUM_FILTER) + \"\\n\"+ \n",
        "                \"GLOBAL_DROPOUT = \" + str(GLOBAL_DROPOUT) \n",
        "                + \"\\n\"+ \"GLOBAL_CONV_TYPE = \" + str(GLOBAL_CONV_TYPE) + \n",
        "                \"\\n\"+ \"RECURRENT_UNITS = \" + str(RECURRENT_UNITS)\n",
        "                  + \"\\n\" + \"RECURRENT_DROPOUT = \" + str(RECURRENT_DROPOUT) \n",
        "                  + \"\\n\" + \"MAXPOOLING = \" + str(MAXPOOLING))\n",
        "                f.close()\n",
        "        start_predict_time = time.time()\n",
        "        # get training graph\n",
        "        df_result = pd.concat([df_train, df_val, df_test]).reset_index(drop=True)\n",
        "      \n",
        "        display_training_performance(df_result, history, eval_history, fold, path, display, publication)\n",
        "        # get calibration graph\n",
        "        calibration_df, uncert_df = get_test_results(model, df_test, fold, modelname, num_predict_samples)\n",
        "        display_calibration_performance(calibration_df, uncert_df, fold, path, display, publication)\n",
        "        end_predict_time = time.time()\n",
        "        predict_time = end_predict_time - start_predict_time\n",
        "        train_times.append(train_time)\n",
        "        predict_times.append(predict_time)\n",
        "        with open(path + \"/times.txt\", \"a\") as f:\n",
        "          f.write(\"FOLD: \" + str(fold)+ \"\\n\"+ \"Train Time: \" + str(train_time)+ \"\\n\"\n",
        "          + \"Predict Time: \" + str(predict_time)+ \"\\n\")\n",
        "          f.close()\n",
        "        # delete fold data\n",
        "        del history\n",
        "        del eval_history\n",
        "        del model\n",
        "    save_pickle(PATH, EXP_NAME, \"unique_check_train\", unique_check_train)\n",
        "    save_pickle(PATH, EXP_NAME, \"unique_check_val\", unique_check_val)\n",
        "    save_pickle(PATH, EXP_NAME, \"unique_check_test\", unique_check_test)\n",
        "    # get overall graph\n",
        "    display_overall_performance(path, unique_check_train, unique_check_val, unique_check_test, display, publication)\n",
        "    display_overall_performance(path, unique_check_train, unique_check_val, unique_check_test, display, publication)\n",
        "\n",
        "def average_len(l):\n",
        "    \"\"\"\n",
        "    Computes the average length of a list of lists\n",
        "    Taken from: https://stackoverflow.com/a/15772649\n",
        "\n",
        "    Args:\n",
        "        l: list of lists.\n",
        "\n",
        "    Returns:\n",
        "        sum(map(len, l))/float(len(l)): Average length of a list of lists.\n",
        "    \"\"\"\n",
        "\n",
        "    return sum(map(len, l))/float(len(l))\n",
        "    "
      ],
      "metadata": {
        "id": "RIXc1k5T9Hjk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY-A108XPzII"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRI0cjgMelzB"
      },
      "outputs": [],
      "source": [
        "make_DeepPulse(SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, SENSOR_DROPOUT, \n",
        "                   GLOBAL_FILTER_SIZE, GLOBAL_NUM_FILTER, \n",
        "                   GLOBAL_DROPOUT, RECURRENT_UNITS, \n",
        "                   RECURRENT_DROPOUT, MAXPOOLING).summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD0XBIc6BSLa"
      },
      "outputs": [],
      "source": [
        "for idx, dataset in enumerate(DATA):\n",
        "  train_model_LOSO(dataset, PATH, EXP_NAME[idx], NUM_EPOCHS, BATCH_SIZE, STRATIFIED, \n",
        "              TEST_SIZE, NUM_PREDICT_SAMPLES, BAND_PASS_LOW, BAND_PASS_HIGH, \n",
        "              BAND_PASS_ORDER, RESAMPLE_FS, DISPLAY, PUBLICATION, \n",
        "              SENSOR_FILTER_SIZE, SENSOR_NUM_FILTER, SENSOR_DROPOUT, \n",
        "              GLOBAL_FILTER_SIZE, GLOBAL_NUM_FILTER, GLOBAL_DROPOUT, \n",
        "              RECURRENT_UNITS, RECURRENT_DROPOUT, MAXPOOLING)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TTOGUC4rHNR_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "jOKj__n6UAnG"
      ],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}